epochs: 200
batch_size: 2
stage: finetune  # pretrain, finetune
notes: 
debug: false
load_pretrained: false

optim:
  lr: 1.0e-5

sch:
  #====== step mod ======
  name: linear  # constant, linear
  warmup_steps: 0
  #====== epoch mod ====== (我自己加的，結果沒比較好)
  # name: plateau           # 你自定義的 scheduler 名稱。這裡設定 'plateau' 代表使用 PyTorch 的 ReduceLROnPlateau（對應在 network.py 分支）。

  # # 指定監控指標是「越小越好」還是「越大越好」。
  # #- min：監控值下降視為改善（常見於 val_loss、val_MSE）。
  # #- max：監控值上升視為改善（常見於 val_R2、accuracy）。
  # mode: min
  # monitor: val_loss       # 可改 val_MAE / val_MSE / val_R2（會傳給 scheduler.step(cur)），告訴程式每個 epoch 結尾要用哪個驗證指標來判斷是否有改善。

  # factor: 0.2             # 當觸發時，學習率會乘上這個倍率。例：lr=1e-4 → 下降為 5e-5。PyTorch 預設0.1。
  # # patience: 3             # 幾個 epoch 沒進步才降 LR。PyTorch 預設10。

  # verbose: true           # 是否在 console 顯示學習率變化訊息（true 時會印出 “Reducing learning rate to …”）。
  # threshold: 0.0          # 認定「有改善」的最小差距。例：threshold=1e-3 時，只有當新 loss 比前次低超過 0.001 才算改善。
  # # 'abs' 絕對差值（absolute difference）：直接比較數值差距是否超過 threshold。例：abs(current - best) > threshold。
  # # 'rel' 相對差值（relative difference）：用比例比較改善幅度（以 best 為基準）。比較相對於 best 的差距是否超過 threshold。例：(current - best) / abs(best) > threshold。
  # threshold_mode: abs

  # # warmup_epochs: 0        # 前幾個 epoch 做 warmup（線性升到 base LR）用整數，當沒填 ratio 時才會用
  # warmup_epoch_ratio: 0.1   # 代表前 10% 的 epoch 做 warmup

paths:
  train_data: 'data/all_data/all_data_YS/tr_all_data_YS_A-D.pkl' # 'data/MPEA/tr1.pkl', 'data/ys_clean/tr1.pkl'
  val_data: 'data/all_data/all_data_YS/vl_all_data_YS_A-D.pkl' # 'data/MPEA/vl1.pkl', 'data/ys_clean/vl1.pkl'
  tokenizer: 'roberta-base' # 'm3rg-iitd/matscibert'
  pretrained: 
  
model:
  name_or_path: 'roberta-base' # 'm3rg-iitd/matscibert'

early_stopping:
  enabled: true        # true 開、false 關
  patience: 20         # 幾個 epoch 沒進步就停止
  monitor: val_R2   # val_loss / val_MAE / val_MSE / val_R2
  mode: max            # 監控 R2 就用 max；其他用 min
  min_delta: 0.0001    # 視為有進步的最小改善幅度
  warmup: 30            # 前幾個 epoch 不啟動早停
